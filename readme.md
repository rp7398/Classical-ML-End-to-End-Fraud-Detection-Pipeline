
# ğŸš€ End-to-End Fraud Detection MLOps Pipeline

A **production-style, end-to-end MLOps project** that demonstrates how modern machine learning systems are **designed, orchestrated, tracked, and deployed** using industry-grade tools.

This project mirrors **real-world ML infrastructure** and is suitable for:
- ğŸ“ MSc / University practicals
- ğŸ’¼ MLOps & Data Science portfolios
- ğŸ§  Interview system-design discussions

---

## ğŸ“Œ Project Objectives

- Build a **complete ML lifecycle pipeline**
- Separate infrastructure from orchestration (production mindset)
- Track experiments and models reliably
- Store ML artifacts externally (cloud-like setup)
- Run everything locally but **cloud-ready**

---

## ğŸ§  What This Project Demonstrates

âœ” Data ingestion and preprocessing  
âœ” Model training and evaluation  
âœ” Experiment tracking & metrics logging  
âœ” Artifact storage (models, metrics, runs)  
âœ” Workflow orchestration  
âœ” Containerized infrastructure  
âœ” Linux-compatible DevOps practices  

---

## ğŸ—ï¸ System Architecture

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Airflow    â”‚
                â”‚ (Orchestration)
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      ML Training Code        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚         MLflow           â”‚
          â”‚ (Experiments & Registry) â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚           MinIO            â”‚
         â”‚   (S3 Artifact Storage)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Metadata â†’ PostgreSQL  
Artifacts â†’ MinIO (S3-compatible)

---

## ğŸ§° Tech Stack

| Layer | Technology |
|-----|------------|
| Language | Python 3.10+ |
| ML | XGBoost |
| Orchestration | Apache Airflow |
| Experiment Tracking | MLflow |
| Database | PostgreSQL |
| Object Storage | MinIO |
| Messaging | Apache Kafka |
| Caching | Redis |
| Containerization | Docker & Docker Compose |
| OS Compatibility | Linux / WSL (Windows) |

---

## ğŸ“ Project Structure

```
fraud-detection-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ fraud_detection/
â”‚   â”œâ”€â”€ infra/          # Core infrastructure (Docker Compose)
â”‚   â”œâ”€â”€ airflow/        # Airflow services (Docker Compose)
â”‚   â”œâ”€â”€ src/            # ML logic
â”‚   â”œâ”€â”€ models/         # Model artifacts
â”‚   â”œâ”€â”€ scripts/        # Shell utilities
â”‚   â””â”€â”€ data/           # Dataset
```

---

## ğŸ§ Why WSL Is Used (Important)

### âŒ Problems with Native Windows

| Issue | Windows |
|-----|--------|
| Shell scripts (`.sh`) | âŒ CRLF issues |
| Docker Linux images | âŒ Inconsistent |
| Makefile support | âŒ Not native |
| Permission handling | âŒ Limited |
| Production similarity | âŒ Low |

### âœ… Benefits of WSL (Linux on Windows)

| Feature | WSL |
|------|-----|
| Linux kernel behavior | âœ… |
| Docker compatibility | âœ… |
| Shell scripting | âœ… |
| Makefile support | âœ… |
| Cloud parity | âœ… |

ğŸ‘‰ **Real-world ML & DevOps systems run on Linux.**
Using WSL ensures:
- Zero cross-platform bugs
- Interview-safe setup
- Production-grade environment

---

## âš™ï¸ Prerequisites

- Docker Desktop
- WSL (Ubuntu recommended)
- Python 3.10+
- Git

---

## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Clone Repository

```bash
git clone <your-repo-url>
cd fraud-detection-pipeline
```

---

### 2ï¸âƒ£ Create Docker Network (One-Time)

```bash
docker network create infra-net
```

---

### 3ï¸âƒ£ Start Infrastructure

```bash
cd fraud_detection/infra
docker compose up -d
```

Starts:
- PostgreSQL
- MLflow
- MinIO
- Kafka
- Redis

---

### 4ï¸âƒ£ Create Airflow Database

```bash
docker exec -it infra-postgres-1 psql -U mlflow -d mlflowdb
```

```sql
CREATE DATABASE airflow;
CREATE USER airflow WITH PASSWORD 'airflow';
GRANT ALL PRIVILEGES ON DATABASE airflow TO airflow;
\q
```

---

### 5ï¸âƒ£ Start Airflow

```bash
cd ../airflow
docker compose up -d
```

---

## ğŸŒ Access Services

| Service | URL |
|------|----|
| Airflow | http://localhost:8081 |
| MLflow | http://localhost:5000 |
| MinIO | http://localhost:9001 |

---

## ğŸ” Default Credentials

### Airflow
```
Username: airflow
Password: airflow
```

### MinIO
```
Username: minioadmin
Password: minioadmin
```

---

## ğŸª£ Purpose of MinIO

MinIO acts as a **local replacement for AWS S3**.

Used for:
- Trained model storage
- MLflow artifacts
- Metrics and logs

This enables:
- Decoupled storage
- Model versioning
- Cloud-ready architecture

---

## ğŸ§ª How to Use the Pipeline

1. Login to Airflow
2. Enable the DAG
3. Trigger the DAG
4. Monitor tasks
5. Verify runs in MLflow
6. Inspect artifacts in MinIO

---

## ğŸ¯ Learning Outcomes

By completing this project, you understand:
- Production ML system design
- MLOps best practices
- Linux-based DevOps workflows
- Cloud-equivalent local setups
- End-to-end ML automation

---

## ğŸš€ Future Enhancements

- Model serving with FastAPI
- CI/CD pipeline
- Monitoring (Prometheus + Grafana)
- Secrets management
- Cloud deployment (AWS/GCP)

---

## ğŸ‘¤ Author

**Rajat Pathak**  
MSc Data Science  
Focused on building **production-grade ML & MLOps systems**

---

â­ If this project helped you, consider starring the repository.
